{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00cd436",
   "metadata": {},
   "source": [
    "# i am using github models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cec7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, List, Dict\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from contextlib import AsyncExitStack\n",
    "from openai import OpenAI\n",
    "from mcp.client.stdio import stdio_client\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb43f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = os.getenv(\"GITHUB_MODEL_NAME\")\n",
    "GUTHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_ENDPOINT = os.getenv(\"GITHUB_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e25c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPOpenAIClient:\n",
    "    \"\"\"A client for interacting with the OpenAI API using the Model Context Protocol (MCP) tools.\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = MODEL):\n",
    "        \"\"\"initilize the openai mcp client\"\"\"\n",
    "        self.model = model\n",
    "        self.session: Optional[ClientSession] = None\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.openai_client = OpenAI(\n",
    "            base_url=GITHUB_ENDPOINT,\n",
    "            api_key=GUTHUB_TOKEN,\n",
    "        )\n",
    "        self.stdio: Optional[Any] = None\n",
    "        self.write: Optional[Any] = None\n",
    "        self.token = GUTHUB_TOKEN\n",
    "        self.endpoint = GITHUB_ENDPOINT\n",
    "\n",
    "    async def connect_to_server(self, server_path: str = 'server.py'):\n",
    "        \"\"\"Connect to the MCP server.\"\"\"\n",
    "\n",
    "        # server config\n",
    "        server_params = StdioServerParameters(\n",
    "            command='python',\n",
    "            args=[server_path],\n",
    "        )\n",
    "\n",
    "        # connect to the server\n",
    "        stdio_transport = await self.exit_stack.enter_async_context(\n",
    "            stdio_client(server_params)\n",
    "        )\n",
    "        self.stdio, self.write = stdio_transport\n",
    "        self.session = await self.exit_stack.enter_async_context(\n",
    "            ClientSession(self.stdio, self.write)\n",
    "        )\n",
    "\n",
    "        # init the connection\n",
    "        await self.session.initialize()\n",
    "\n",
    "        # list the available tools\n",
    "        tools_result = await self.session.list_tools()\n",
    "        print(\"\\nConnected to server with tools:\")\n",
    "        for tool in tools_result.tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "    async def get_mcp_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get the list of tools available in the MCP session.\"\"\"\n",
    "        if not self.session:\n",
    "            raise RuntimeError(\"Session is not initialized. Call connect_to_server first.\")\n",
    "        \n",
    "        tools_result = await self.session.list_tools()\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"parameters\": tool.inputSchema,\n",
    "                }\n",
    "            }\n",
    "            for tool in tools_result.tools\n",
    "        ]\n",
    "    \n",
    "    async def process_query(self, query: str) -> str:\n",
    "        \"\"\"Process a query using OpenAI and MCP tools.\"\"\"\n",
    "\n",
    "        # get tools \n",
    "        tools = await self.get_mcp_tools()\n",
    "\n",
    "        # initial openai response\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query\n",
    "                }\n",
    "            ],\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "        )\n",
    "        assistant_message = response.choices[0].message\n",
    "\n",
    "        # initilize conversation with user query and assisant response\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            },\n",
    "            assistant_message\n",
    "        ]\n",
    "\n",
    "        # handle tool calls if present\n",
    "        if assistant_message.tool_calls:\n",
    "            for tool_call in assistant_message.tool_calls:\n",
    "                # execute tool call\n",
    "                result = await self.session.call_tool(\n",
    "                    name=tool_call.function.name,\n",
    "                    arguments=json.loads(tool_call.function.arguments)\n",
    "                )\n",
    "\n",
    "                # add tool call to conversation\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": result.content[0].text,\n",
    "                })\n",
    "            \n",
    "            # get the final response after tool calls\n",
    "            final_response = self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\",\n",
    "            )\n",
    "\n",
    "            return final_response.choices[0].message.content\n",
    "        \n",
    "        return assistant_message.content\n",
    "    \n",
    "    async def cleanup(self):\n",
    "        \"\"\"Cleanup the session and exit stack.\"\"\"\n",
    "        await self.exit_stack.aclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10799bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to run the MCP OpenAI client.\"\"\"\n",
    "    client = MCPOpenAIClient()\n",
    "    await client.connect_to_server()\n",
    "\n",
    "    query = query = \"What is our company's vacation policy?\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "\n",
    "    response = await client.process_query(query)\n",
    "    print(f\"\\nResponse: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34aadf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connected to server with tools:\n",
      "  - get_knowledge_base: Retrieve the entire knowledge base as a formatted string.\n",
      "\n",
      "Returns:\n",
      "    A formatted string containing all Q&A pairs from the knowledge base.\n",
      "\n",
      "\n",
      "Query: What is our company's vacation policy?\n",
      "\n",
      "Response: Our company's vacation policy is as follows:\n",
      "\n",
      "- Full-time employees are entitled to 20 paid vacation days per year.\n",
      "- Vacation days can be used after completing 6 months of employment.\n",
      "- You may carry over up to 5 unused vacation days to the next year.\n",
      "- Vacation requests must be submitted at least 2 weeks in advance through the HR portal.\n",
      "\n",
      "Let me know if you need information on how to submit a request or have any other questions!\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49183f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1-MCP-Getting-Started",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
